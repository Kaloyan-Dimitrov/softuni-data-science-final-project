{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import collection, imread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from datetime import datetime\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is the public opinion about a company correlated to it's market value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A company's market value is variable and depends on a lot of factors. The price is a reflection of the company's perceived value - what the public is willing to pay for a piece of the company. It can and will rise and fall, based on a variety of factors in the global landscape and within the company itself. One of which is becoming more influential than ever - people's opinion on social media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze this correlation we'll look at two datasets. The first one contains over 3 million unique tweets with their information such as tweet id, author of the tweet, post date, the text body of the tweet, and the number of comments, likes, and retweets of tweets matched with the related company.\n",
    "\n",
    "The second one will just have daily stock price records (from the Forbes2000) for us to make a reference with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Acquisition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first let's read the tweets dataset into pandas and inspect a small sample from the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2335486</th>\n",
       "      <td>979745363824439296</td>\n",
       "      <td>TickerReport</td>\n",
       "      <td>1522424472</td>\n",
       "      <td>Verde Servicos Internacionais S.A. Has $5.59 M...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359947</th>\n",
       "      <td>611969714353479680</td>\n",
       "      <td>johnoduk</td>\n",
       "      <td>1434739924</td>\n",
       "      <td>$GOOG - EU Demands Major Changes to Google's S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304664</th>\n",
       "      <td>973944831062966273</td>\n",
       "      <td>PortfolioBuzz</td>\n",
       "      <td>1521041517</td>\n",
       "      <td>Highest scoring stories for #SP500 under one w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854137</th>\n",
       "      <td>1060225248522461184</td>\n",
       "      <td>RaindropsOhMy</td>\n",
       "      <td>1541612371</td>\n",
       "      <td>$AAPL big quick rip here to $208.7 would be ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276902</th>\n",
       "      <td>1125418097332985857</td>\n",
       "      <td>SagarNandi</td>\n",
       "      <td>1557155558</td>\n",
       "      <td>(1) $AAPL is overvalued in CUE scorecard and (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id         writer   post_date  \\\n",
       "2335486   979745363824439296   TickerReport  1522424472   \n",
       "359947    611969714353479680       johnoduk  1434739924   \n",
       "2304664   973944831062966273  PortfolioBuzz  1521041517   \n",
       "2854137  1060225248522461184  RaindropsOhMy  1541612371   \n",
       "3276902  1125418097332985857     SagarNandi  1557155558   \n",
       "\n",
       "                                                      body  comment_num  \\\n",
       "2335486  Verde Servicos Internacionais S.A. Has $5.59 M...            0   \n",
       "359947   $GOOG - EU Demands Major Changes to Google's S...            0   \n",
       "2304664  Highest scoring stories for #SP500 under one w...            0   \n",
       "2854137  $AAPL big quick rip here to $208.7 would be ni...            0   \n",
       "3276902  (1) $AAPL is overvalued in CUE scorecard and (...            0   \n",
       "\n",
       "         retweet_num  like_num  \n",
       "2335486            0         0  \n",
       "359947             0         0  \n",
       "2304664            0         0  \n",
       "2854137            0         0  \n",
       "3276902            0         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('./top-companies-tweets/Tweet.csv')\n",
    "tweets.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2052008</th>\n",
       "      <td>1019341037465001984</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071012</th>\n",
       "      <td>870363870002630656</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855525</th>\n",
       "      <td>1045672382466334726</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186065</th>\n",
       "      <td>608130665914056705</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285037</th>\n",
       "      <td>598526844032299009</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id ticker_symbol\n",
       "2052008  1019341037465001984         GOOGL\n",
       "3071012   870363870002630656          MSFT\n",
       "3855525  1045672382466334726          TSLA\n",
       "2186065   608130665914056705          AMZN\n",
       "3285037   598526844032299009          TSLA"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_company = pd.read_csv('./top-companies-tweets/Company_Tweet.csv')\n",
    "tweets_company.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So next up let's read the datasets for each of the stocks, which we are monitoring. We will save them in a dictionary with the key, being the company's tick name and the value - it's stock prices over time dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MSFT</th>\n",
       "      <th>3565</th>\n",
       "      <td>19-04-2000</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>40.718750</td>\n",
       "      <td>53715400</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>39.343750</td>\n",
       "      <td>24.931646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>01-10-1996</td>\n",
       "      <td>8.179688</td>\n",
       "      <td>8.234375</td>\n",
       "      <td>69124800</td>\n",
       "      <td>8.367188</td>\n",
       "      <td>8.257813</td>\n",
       "      <td>5.232873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <th>1413</th>\n",
       "      <td>27-12-2002</td>\n",
       "      <td>18.430000</td>\n",
       "      <td>19.969999</td>\n",
       "      <td>21972800</td>\n",
       "      <td>20.100000</td>\n",
       "      <td>18.860001</td>\n",
       "      <td>18.860001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <th>7988</th>\n",
       "      <td>10-08-2012</td>\n",
       "      <td>22.096430</td>\n",
       "      <td>22.096786</td>\n",
       "      <td>194938800</td>\n",
       "      <td>22.205713</td>\n",
       "      <td>22.203571</td>\n",
       "      <td>19.174887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MSFT</th>\n",
       "      <th>7446</th>\n",
       "      <td>24-09-2015</td>\n",
       "      <td>43.270000</td>\n",
       "      <td>43.450001</td>\n",
       "      <td>27905600</td>\n",
       "      <td>44.130001</td>\n",
       "      <td>43.910000</td>\n",
       "      <td>39.618057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7781</th>\n",
       "      <td>24-01-2017</td>\n",
       "      <td>62.939999</td>\n",
       "      <td>63.200001</td>\n",
       "      <td>24672900</td>\n",
       "      <td>63.740002</td>\n",
       "      <td>63.520000</td>\n",
       "      <td>59.280830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <th>9832</th>\n",
       "      <td>10-12-2019</td>\n",
       "      <td>66.464996</td>\n",
       "      <td>67.150002</td>\n",
       "      <td>90420400</td>\n",
       "      <td>67.517502</td>\n",
       "      <td>67.120003</td>\n",
       "      <td>66.333351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <th>2673</th>\n",
       "      <td>31-12-2007</td>\n",
       "      <td>92.449997</td>\n",
       "      <td>93.809998</td>\n",
       "      <td>5755200</td>\n",
       "      <td>94.370003</td>\n",
       "      <td>92.639999</td>\n",
       "      <td>92.639999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <th>8033</th>\n",
       "      <td>24-01-2018</td>\n",
       "      <td>91.580002</td>\n",
       "      <td>92.550003</td>\n",
       "      <td>33277500</td>\n",
       "      <td>93.430000</td>\n",
       "      <td>91.820000</td>\n",
       "      <td>87.605545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <th>586</th>\n",
       "      <td>23-10-2012</td>\n",
       "      <td>5.474000</td>\n",
       "      <td>5.476000</td>\n",
       "      <td>3745000</td>\n",
       "      <td>5.712000</td>\n",
       "      <td>5.678000</td>\n",
       "      <td>5.678000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date        Low       Open     Volume       High      Close  \\\n",
       "MSFT 3565  19-04-2000  39.062500  40.718750   53715400  40.750000  39.343750   \n",
       "     2669  01-10-1996   8.179688   8.234375   69124800   8.367188   8.257813   \n",
       "AMZN 1413  27-12-2002  18.430000  19.969999   21972800  20.100000  18.860001   \n",
       "AAPL 7988  10-08-2012  22.096430  22.096786  194938800  22.205713  22.203571   \n",
       "MSFT 7446  24-09-2015  43.270000  43.450001   27905600  44.130001  43.910000   \n",
       "     7781  24-01-2017  62.939999  63.200001   24672900  63.740002  63.520000   \n",
       "AAPL 9832  10-12-2019  66.464996  67.150002   90420400  67.517502  67.120003   \n",
       "AMZN 2673  31-12-2007  92.449997  93.809998    5755200  94.370003  92.639999   \n",
       "MSFT 8033  24-01-2018  91.580002  92.550003   33277500  93.430000  91.820000   \n",
       "TSLA 586   23-10-2012   5.474000   5.476000    3745000   5.712000   5.678000   \n",
       "\n",
       "           Adjusted Close  \n",
       "MSFT 3565       24.931646  \n",
       "     2669        5.232873  \n",
       "AMZN 1413       18.860001  \n",
       "AAPL 7988       19.174887  \n",
       "MSFT 7446       39.618057  \n",
       "     7781       59.280830  \n",
       "AAPL 9832       66.333351  \n",
       "AMZN 2673       92.639999  \n",
       "MSFT 8033       87.605545  \n",
       "TSLA 586         5.678000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_df = {}\n",
    "for name in glob.glob('./stocks/*'):\n",
    "    stocks_df[name.split('\\\\')[-1].split('.')[0]] = pd.read_csv(name)\n",
    "stocks = pd.concat(stocks_df)\n",
    "stocks.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Tidying and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's combine the two tables from the twitter dataset, convert the dates to a datetime object and rename the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.merge(tweets, tweets_company, on = \"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113378</th>\n",
       "      <td>568068696410730497</td>\n",
       "      <td>laurenholmesNYC</td>\n",
       "      <td>Top 10 holdings $AAPL $MSFT $GOOG $FB $AMZN $I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2015-02-18 15:25:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552538</th>\n",
       "      <td>1095663088060239873</td>\n",
       "      <td>AznOptions</td>\n",
       "      <td>Will take $NFLX profits and roll them into mor...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-02-13 12:36:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380328</th>\n",
       "      <td>759270364228780032</td>\n",
       "      <td>PortfolioBuzz</td>\n",
       "      <td>Highest scoring stories for #SP500 under one w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-07-30 06:12:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363755</th>\n",
       "      <td>916399180876099585</td>\n",
       "      <td>MacHashNews</td>\n",
       "      <td>iPhone X TrueDepth supply issues likely to cle...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2017-10-06 20:26:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020200</th>\n",
       "      <td>1159447012846329859</td>\n",
       "      <td>bs_marker</td>\n",
       "      <td>The first informative #App on Pivot Points.Sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-08-08 12:51:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id           writer  \\\n",
       "113378    568068696410730497  laurenholmesNYC   \n",
       "3552538  1095663088060239873       AznOptions   \n",
       "1380328   759270364228780032    PortfolioBuzz   \n",
       "2363755   916399180876099585      MacHashNews   \n",
       "4020200  1159447012846329859        bs_marker   \n",
       "\n",
       "                                                      body  comment_num  \\\n",
       "113378   Top 10 holdings $AAPL $MSFT $GOOG $FB $AMZN $I...            0   \n",
       "3552538  Will take $NFLX profits and roll them into mor...            1   \n",
       "1380328  Highest scoring stories for #SP500 under one w...            0   \n",
       "2363755  iPhone X TrueDepth supply issues likely to cle...            0   \n",
       "4020200  The first informative #App on Pivot Points.Sto...            0   \n",
       "\n",
       "         retweet_num  like_num ticker_symbol                date  \n",
       "113378             0         1          AMZN 2015-02-18 15:25:06  \n",
       "3552538            0         1          AAPL 2019-02-13 12:36:51  \n",
       "1380328            0         0          AAPL 2016-07-30 06:12:16  \n",
       "2363755            0         0          AAPL 2017-10-06 20:26:05  \n",
       "4020200            0         0          AMZN 2019-08-08 12:51:24  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"date\"] = pd.to_datetime(tweets.post_date, unit='s')\n",
    "tweets = tweets.drop(columns=\"post_date\")\n",
    "tweets.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see what timeframe does our dataset cover, by getting the data of the earliest and latest tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2015-01-01 00:00:57'), Timestamp('2019-12-31 23:55:53'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.date.min(), tweets.date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it has data from 01.01.2015 to 31.12.2019, so basically from 2015 to the beginning of 2020. Knowing this we can filter out the stock prices to be only in this period of time. But first we have to covert the \"Date\" column to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_date(date_string):\n",
    "    return datetime.strptime(date_string, \"%d-%m-%Y\")\n",
    "stocks.Date = pd.to_datetime(stocks.Date.apply(string_to_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MSFT</th>\n",
       "      <th>7292</th>\n",
       "      <td>2015-02-13</td>\n",
       "      <td>43.150002</td>\n",
       "      <td>43.380001</td>\n",
       "      <td>40264900</td>\n",
       "      <td>43.869999</td>\n",
       "      <td>43.869999</td>\n",
       "      <td>38.792679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8326</th>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>116.849998</td>\n",
       "      <td>118.620003</td>\n",
       "      <td>26097700</td>\n",
       "      <td>118.709999</td>\n",
       "      <td>117.910004</td>\n",
       "      <td>114.934296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <th>4665</th>\n",
       "      <td>2015-11-27</td>\n",
       "      <td>672.099976</td>\n",
       "      <td>680.799988</td>\n",
       "      <td>1966800</td>\n",
       "      <td>680.989990</td>\n",
       "      <td>673.260010</td>\n",
       "      <td>673.260010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <th>8386</th>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>135.720001</td>\n",
       "      <td>137.449997</td>\n",
       "      <td>33042600</td>\n",
       "      <td>137.660004</td>\n",
       "      <td>136.949997</td>\n",
       "      <td>133.987885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <th>3692</th>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>1228.310059</td>\n",
       "      <td>1235.989990</td>\n",
       "      <td>807300</td>\n",
       "      <td>1249.089966</td>\n",
       "      <td>1248.839966</td>\n",
       "      <td>1248.839966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AMZN</th>\n",
       "      <th>4693</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>606.000000</td>\n",
       "      <td>619.659973</td>\n",
       "      <td>5512900</td>\n",
       "      <td>624.140015</td>\n",
       "      <td>607.049988</td>\n",
       "      <td>607.049988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>890.280029</td>\n",
       "      <td>891.500000</td>\n",
       "      <td>4984700</td>\n",
       "      <td>908.539978</td>\n",
       "      <td>906.830017</td>\n",
       "      <td>906.830017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <th>7384</th>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>45.029999</td>\n",
       "      <td>45.650002</td>\n",
       "      <td>49835300</td>\n",
       "      <td>46.279999</td>\n",
       "      <td>45.259998</td>\n",
       "      <td>40.568584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <th>9010</th>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>26.705000</td>\n",
       "      <td>26.924999</td>\n",
       "      <td>107210000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.932501</td>\n",
       "      <td>25.296234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <th>1656</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>50.150002</td>\n",
       "      <td>50.858002</td>\n",
       "      <td>15760500</td>\n",
       "      <td>51.147999</td>\n",
       "      <td>50.501999</td>\n",
       "      <td>50.501999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date          Low         Open     Volume         High  \\\n",
       "MSFT 7292 2015-02-13    43.150002    43.380001   40264900    43.869999   \n",
       "     8326 2019-03-26   116.849998   118.620003   26097700   118.709999   \n",
       "AMZN 4665 2015-11-27   672.099976   680.799988    1966800   680.989990   \n",
       "MSFT 8386 2019-06-20   135.720001   137.449997   33042600   137.660004   \n",
       "GOOG 3692 2019-04-22  1228.310059  1235.989990     807300  1249.089966   \n",
       "AMZN 4693 2016-01-08   606.000000   619.659973    5512900   624.140015   \n",
       "     5004 2017-04-04   890.280029   891.500000    4984700   908.539978   \n",
       "MSFT 7384 2015-06-26    45.029999    45.650002   49835300    46.279999   \n",
       "AAPL 9010 2016-09-02    26.705000    26.924999  107210000    27.000000   \n",
       "TSLA 1656 2017-01-26    50.150002    50.858002   15760500    51.147999   \n",
       "\n",
       "                 Close  Adjusted Close  \n",
       "MSFT 7292    43.869999       38.792679  \n",
       "     8326   117.910004      114.934296  \n",
       "AMZN 4665   673.260010      673.260010  \n",
       "MSFT 8386   136.949997      133.987885  \n",
       "GOOG 3692  1248.839966     1248.839966  \n",
       "AMZN 4693   607.049988      607.049988  \n",
       "     5004   906.830017      906.830017  \n",
       "MSFT 7384    45.259998       40.568584  \n",
       "AAPL 9010    26.932501       25.296234  \n",
       "TSLA 1656    50.501999       50.501999  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = stocks[(stocks.Date >= '01-01-2015') & (stocks.Date < '01-01-2020')]\n",
    "stocks.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we don't have data for every day, because the stock market functions only on workdays, unlike twitter.  We will find a way to work around this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets strip the data down to just one column - the value, which we will calculate by getting the mean of the Open and Close prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <th>1660</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>19794000</td>\n",
       "      <td>50.229000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <th>3357</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>1554600</td>\n",
       "      <td>1071.609985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <th>1138</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>31309500</td>\n",
       "      <td>42.134001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MSFT</th>\n",
       "      <th>8416</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>30791600</td>\n",
       "      <td>137.494995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8392</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>30043000</td>\n",
       "      <td>134.265007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>21384300</td>\n",
       "      <td>107.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <th>4904</th>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>3412600</td>\n",
       "      <td>786.359985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <th>8657</th>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>145460400</td>\n",
       "      <td>31.902499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <th>1678</th>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>30390500</td>\n",
       "      <td>49.418001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <th>9809</th>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>75864400</td>\n",
       "      <td>64.251247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date     Volume        Value\n",
       "TSLA 1660 2017-02-01   19794000    50.229000\n",
       "GOOG 3357 2017-12-18    1554600  1071.609985\n",
       "TSLA 1138 2015-01-06   31309500    42.134001\n",
       "MSFT 8416 2019-08-02   30791600   137.494995\n",
       "     8392 2019-06-28   30043000   134.265007\n",
       "     8175 2018-08-16   21384300   107.970001\n",
       "AMZN 4904 2016-11-08    3412600   786.359985\n",
       "AAPL 8657 2015-04-13  145460400    31.902499\n",
       "TSLA 1678 2017-02-28   30390500    49.418001\n",
       "AAPL 9809 2019-11-06   75864400    64.251247"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks[\"Value\"] = (stocks.Open + stocks.Close) / 2\n",
    "stocks = stocks.drop(columns=['Low', 'Open', 'High', 'Close', 'Adjusted Close'])\n",
    "stocks.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a little inconvenient to have the stock name as an index instead of it being a regular column. We will fix that and also change the column names to match the twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = stocks.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6290 entries, 8589 to 2393\n",
      "Data columns (total 4 columns):\n",
      "ticker_symbol    6290 non-null object\n",
      "date             6290 non-null datetime64[ns]\n",
      "volume           6290 non-null int64\n",
      "value            6290 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(1)\n",
      "memory usage: 245.7+ KB\n"
     ]
    }
   ],
   "source": [
    "stocks.columns = [\"ticker_symbol\", \"date\", \"volume\", \"value\"]\n",
    "stocks.sample(10)\n",
    "stocks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So next up lets take a look at the datatypes and null values for the twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4336445 entries, 0 to 4336444\n",
      "Data columns (total 8 columns):\n",
      "tweet_id         4336445 non-null int64\n",
      "writer           4280526 non-null object\n",
      "body             4336445 non-null object\n",
      "comment_num      4336445 non-null int64\n",
      "retweet_num      4336445 non-null int64\n",
      "like_num         4336445 non-null int64\n",
      "ticker_symbol    4336445 non-null object\n",
      "date             4336445 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(4), object(3)\n",
      "memory usage: 297.8+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info(null_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good, except the ticker_symbol which should be a category. Also the writer column has quite a few missing records, but we won't be using it for our model and analysis, so we can discard it altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550441509175443456</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01 00:00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550441672312512512</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01 00:01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550441732014223360</td>\n",
       "      <td>S&amp;P100 #Stocks Performance $HD $LOW $SBUX $TGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2015-01-01 00:01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550442977802207232</td>\n",
       "      <td>$GM $TSLA: Volkswagen Pushes 2014 Record Recal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2015-01-01 00:06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550443807834402816</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01 00:10:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>550443807834402816</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2015-01-01 00:10:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>550443808606126081</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01 00:10:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               body  \\\n",
       "0  550441509175443456  lx21 made $10,008  on $AAPL -Check it out! htt...   \n",
       "1  550441672312512512  Insanity of today weirdo massive selling. $aap...   \n",
       "2  550441732014223360  S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...   \n",
       "3  550442977802207232  $GM $TSLA: Volkswagen Pushes 2014 Record Recal...   \n",
       "4  550443807834402816  Swing Trading: Up To 8.91% Return In 14 Days h...   \n",
       "5  550443807834402816  Swing Trading: Up To 8.91% Return In 14 Days h...   \n",
       "6  550443808606126081  Swing Trading: Up To 8.91% Return In 14 Days h...   \n",
       "\n",
       "   comment_num  retweet_num  like_num ticker_symbol                date  \n",
       "0            0            0         1          AAPL 2015-01-01 00:00:57  \n",
       "1            0            0         0          AAPL 2015-01-01 00:01:36  \n",
       "2            0            0         0          AMZN 2015-01-01 00:01:50  \n",
       "3            0            0         1          TSLA 2015-01-01 00:06:47  \n",
       "4            0            0         1          AAPL 2015-01-01 00:10:05  \n",
       "5            0            0         1          TSLA 2015-01-01 00:10:05  \n",
       "6            0            0         1          AAPL 2015-01-01 00:10:05  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.ticker_symbol = tweets.ticker_symbol.astype('category')\n",
    "tweets = tweets.drop(columns=[\"writer\"])\n",
    "tweets.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there seem to be a lot of duplicate bodies in our dataset. We want to remove them and this is exactly what the following code does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop_duplicates(subset=[\"body\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Text Preparation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start working with the text, we have to prepare it and take a quick look at some statistics about it. First let's convert all the tweets' bodies into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.body = tweets.body.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK provides a small corpus of stop words that we will load into a list, based on which we'll later filter them out from the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "stopwords.append(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split the text into single words and remove all the stopwords from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1334484</th>\n",
       "      <td>753537489902538752</td>\n",
       "      <td>[prime, day, sets, sales, record, amazon, read...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2016-07-14 10:31:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578911</th>\n",
       "      <td>959170311810879490</td>\n",
       "      <td>[googl, misses]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2018-02-01 21:03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825433</th>\n",
       "      <td>679694716099805185</td>\n",
       "      <td>[swhc, fb, amzn, nke, panw, atvi, ea, fuked, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2015-12-23 16:07:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637513</th>\n",
       "      <td>1106576874661203971</td>\n",
       "      <td>[tsla, model3, vins, per, model3vins, 3, 15, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2019-03-15 15:24:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736607</th>\n",
       "      <td>660255379851313152</td>\n",
       "      <td>[lqd, ishares, iboxx, investment, grade, corpo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2015-10-31 00:42:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id  \\\n",
       "1334484   753537489902538752   \n",
       "2578911   959170311810879490   \n",
       "825433    679694716099805185   \n",
       "3637513  1106576874661203971   \n",
       "736607    660255379851313152   \n",
       "\n",
       "                                                      body  comment_num  \\\n",
       "1334484  [prime, day, sets, sales, record, amazon, read...            0   \n",
       "2578911                                    [googl, misses]            0   \n",
       "825433   [swhc, fb, amzn, nke, panw, atvi, ea, fuked, t...            0   \n",
       "3637513  [tsla, model3, vins, per, model3vins, 3, 15, 2...            0   \n",
       "736607   [lqd, ishares, iboxx, investment, grade, corpo...            0   \n",
       "\n",
       "         retweet_num  like_num ticker_symbol                date  \n",
       "1334484            0         0          AMZN 2016-07-14 10:31:52  \n",
       "2578911            0         0         GOOGL 2018-02-01 21:03:17  \n",
       "825433             0         0          AMZN 2015-12-23 16:07:03  \n",
       "3637513            0         0          TSLA 2019-03-15 15:24:20  \n",
       "736607             0         0          AMZN 2015-10-31 00:42:04  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def string_into_words(str): \n",
    "    return [w for w in re.split(\"\\W+\", str) if w not in stopwords]\n",
    "tweets.body = tweets.body.apply(string_into_words)\n",
    "tweets.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the frequency distribution of the words (how many times is each word appears in the tweets). Just because the dataset is too large to analyze every observation. To combat this we will take a smaller sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1362011</th>\n",
       "      <td>757926087368269824</td>\n",
       "      <td>[mobileye, drops, 10, ends, tesla, relationshi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2016-07-26 13:10:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439937</th>\n",
       "      <td>1080839775161077760</td>\n",
       "      <td>[50, dma, resistance, today, kiq, vips, ntes, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-01-03 14:54:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974882</th>\n",
       "      <td>1022534616014643200</td>\n",
       "      <td>[active, traders, try, one, free, trading, gui...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2018-07-26 17:30:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id  \\\n",
       "1362011   757926087368269824   \n",
       "3439937  1080839775161077760   \n",
       "2974882  1022534616014643200   \n",
       "\n",
       "                                                      body  comment_num  \\\n",
       "1362011  [mobileye, drops, 10, ends, tesla, relationshi...            0   \n",
       "3439937  [50, dma, resistance, today, kiq, vips, ntes, ...            0   \n",
       "2974882  [active, traders, try, one, free, trading, gui...            0   \n",
       "\n",
       "         retweet_num  like_num ticker_symbol                date  \n",
       "1362011            2         0          TSLA 2016-07-26 13:10:35  \n",
       "3439937            0         0          GOOG 2019-01-03 14:54:18  \n",
       "2974882            0         0         GOOGL 2018-07-26 17:30:24  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_sample = tweets.sample(10000, random_state=10)\n",
    "tweets_sample.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = tweets_sample.body.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aapl', 4144),\n",
       " ('http', 3732),\n",
       " ('tsla', 3160),\n",
       " ('amzn', 2310),\n",
       " ('com', 2291),\n",
       " ('apple', 1650),\n",
       " ('read', 1280),\n",
       " ('us', 1280),\n",
       " ('owler', 1204),\n",
       " ('https', 1139),\n",
       " ('goog', 1135),\n",
       " ('msft', 1099),\n",
       " ('googl', 1000),\n",
       " ('tesla', 840),\n",
       " ('fb', 823),\n",
       " ('stock', 821),\n",
       " ('amazon', 670),\n",
       " ('dlvr', 621),\n",
       " ('google', 603),\n",
       " ('stocks', 595),\n",
       " ('microsoft', 567),\n",
       " ('inc', 555),\n",
       " ('ly', 550),\n",
       " ('new', 538),\n",
       " ('nflx', 536),\n",
       " ('1', 497),\n",
       " ('news', 484),\n",
       " ('spy', 477),\n",
       " ('like', 462),\n",
       " ('market', 454)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 30 words consist mainly of companies' names and stock ticks as we can expect. But at the bottom there we can see the word \"like\". This is very important, because it expresses some sort of sentiment."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6c8b04f14d242a79d2f2c97ca18fbe5de19a6e318158e3ea606ce00f4b7f1f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
